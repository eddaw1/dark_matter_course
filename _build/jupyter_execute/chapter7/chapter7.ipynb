{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754c6a25",
   "metadata": {},
   "source": [
    "# Noise in axion experiments\n",
    "\n",
    "## Fluctuations and the radiometer equation\n",
    "\n",
    "The level of fluctuations in the noise background is regulated by the radiometer equation, which we now derive. Consider a classical system which has available to it a contiouous set of states having energy $E$. The system is in thermal equilibrium at a temperature $T$. We do not know how many available states there are at each energy $E$, or indeed what the system consists of, but we do know that it is governed by Maxwell Bolzmann statistics. The probability density $p(E)$ of the system having energy $E$ can be \n",
    "\n",
    "$$\\begin{align*}\n",
    "p(E)=A(T)e^{-\\frac{E}{k_BT}},\n",
    "\\end{align*}$$\n",
    "\n",
    "where $A(T)$ is the number of available states at energy $E$, and is generally a function of the temperature of the system. It will make the derivation easier to write $\\beta=1/(k_BT)$, so that we obtain\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(E)=A(\\beta)e^{-\\beta E}.\n",
    "\\end{align*}$$\n",
    "\n",
    "The probability density obeys a normalisation condition, so that\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\int_{E=0}^\\infty p(E)\\,dE=\\int A(\\beta)e^{-\\beta E}\\,dE=1,\n",
    "\\end{align*}$$\n",
    "\n",
    "where during this derivation all integrals will be between $E=0$ and $E=+\\infty$. We differentiate this expression with respect to $\\beta$ and obtain\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{d}{d\\beta}\\int A(\\beta)e^{-\\beta E}\\,dE&=0,\n",
    "\\end{align*}$$\n",
    "\n",
    "We bring the differential inside the integral over energies and apply the product rule to differentiate first $A(\\beta)$ and then $e^{-\\beta E}$, both of which are $\\beta$ dependent.\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\int \\left(\\frac{dA}{d\\beta}e^{-\\beta E}-E\\,A(\\beta)e^{-\\beta E}\\right)\\,dE&=0 \\\\\n",
    "\\int \\frac{dA}{d\\beta}e^{-\\beta E}\\,dE&=\\int\\,E\\,A(\\beta)e^{-\\beta E}.\n",
    "\\end{align*}$$\n",
    "\n",
    "The right hand side is $\\int\\,Ep(E)dE$, which is $\\overline{E}$, the average value of the energy. The $dA/d\\beta$ on the left has no $E$ dependence and can be pulled out of the integral. In addition, we can introduce $A/A$ on the right. We obtain\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{1}{A}\\frac{dA}{d\\beta}\\int\\,A\\,e^{-\\beta E}\\,dE &=\\overline{E}. \n",
    "\\end{align*}$$\n",
    "\n",
    "The integral is $1$ because it is equal to $\\int\\,p(E)dE$. Hence we can write\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{dA}{d\\beta}&=A\\overline{E}.\n",
    "\\tag{7.1}\n",
    "\\end{align*}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80333b",
   "metadata": {},
   "source": [
    "We next return to the expression for $\\overline{E}$, the average energy.\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\overline{E}&=\\int\\,E\\,p(E)\\,dE=\\int E\\,A(\\beta)e^{-\\beta E}\\,dE\n",
    "\\end{align*}$$\n",
    "\n",
    "Differentiating,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{d\\overline{E}}{d\\beta}&=\\int\\frac{dA}{d\\beta}\\,E\\,e^{-\\beta E}\\,dE-\\int\\,A\\,E^2\\,e^{-\\beta E}\\,dE \\\\\n",
    "&=\\int\\frac{dA}{d\\beta}\\,E\\,e^{-\\beta E}\\,dE-\\overline{E^2}.\n",
    "\\end{align*}$$\n",
    "\n",
    "We substitute in from Equation 7.1, and factor the $\\overline{E}$ out of the left hand integral.\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{d\\overline{E}}{d\\beta}&=\\overline{E}\\int\\,E\\,A\\,e^{-\\beta E}\\,dE-\\overline{E^2}. \\\\\n",
    "&=\\overline{E}^2-\\overline{E^2}.\n",
    "\\tag{7.2}\n",
    "\\end{align*}$$\n",
    "\n",
    "Next we re-introduce temperature $T$ by writing\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{d\\overline{E}}{d\\beta}&=\\frac{d\\overline{E}}{dT}\\frac{dT}{d\\beta}. \n",
    "\\end{align*}$$\n",
    "\n",
    "Now, $\\beta=1/(k_BT)$, so that $d\\beta/dT=-1/(k_BT^2)$, and $dT/d\\beta=-k_BT^2$. Substituting this in to Equation 7.2, we get\n",
    "\n",
    "$$\\begin{align*}\n",
    "k_B T^2\\frac{d\\overline{E}}{dT}&=\\overline{E^2}-\\overline{E}^2. \n",
    "\\end{align*}$$\n",
    "\n",
    "Now, the difference between the average of the square of a quantity and the square of the average of a quantity is also known as the variance of that quantity. We therefore write $\\sigma_E^2=\\overline{E^2}-\\overline{E}^2$, so that we arrive at\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\sigma_E^2&=k_BT^2\\frac{d\\overline{E}}{dT}.\n",
    "\\tag{7.3}\n",
    "\\end{align*}$$\n",
    "\n",
    "This result was first derived, as far as I know, by J. Willard Gibbs in his book Elementary Principles In Statistical Mechanics, published in 1901. Though the title makes it seem like a textbook, in fact this is the book where Gibbs laid out the foundations of statistical mechanics. The derivation is on pages 68-72. Its importance to axion searches will become clear, but it is also of central importance in radio astronomy and any other field where measurements of a signal on top of noise in thermal equilibrium are being made. This is, of course, most experiments, so it is a very important result. I think this result is one of the unsung heroes of physics, because of its immense generality and utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cdaa1",
   "metadata": {},
   "source": [
    "## The radiometer equation applied to Johnson noise.\n",
    "\n",
    "For Johnson noise, we know that the average power emitted by a resistor at temperature $T$ matched to a transmission line is $P=k_B T B$, where $B$ is the bandwidth. Therefore, in a time interval $t$, the average amount of energy transmitted by the noise source is $\\overline{E}=k_B T B t$. We insert this average energy into Gibb's radiometer equation, 7.3, and obtain\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\sigma_E^2&=k_B^2 T^2 B t \\\\\n",
    "\\sigma_E&= k_B T\\sqrt{Bt} \\\\\n",
    "\\frac{\\sigma_E}{\\overline{E}}&=\\frac{k_B T \\sqrt{Bt}}{k_B T B t}. \\\\\n",
    "\\frac{\\sigma_E}{\\overline{E}}&=\\frac{1}{\\sqrt{Bt}}. \n",
    "\\tag{7.4}\n",
    "\\end{align*}$$\n",
    "\n",
    "Let us interpret this result. Suppose we measure the energy incident from our resistive source at temperature $T$ over a time interval $t$. What result can we hope to get? It won't be exactly the average $\\overline{E}$, there will be some spread about this value. The root mean square, or standard deviation, of that spread is $\\sigma_E$. If we divide the energy recieved by the time interval over which it was received, $t$, then $\\overline{E}/t$ is an estimate of the noise power $P_N$ emitted by the source. The spread in the recevied value is $\\sigma_N=\\sigma_E/t$. Because both $\\overline{E}$ and $\\sigma_E$ have been divided by the same time interval $t$, their ratio remains the same, so we can write\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{\\sigma_N}{P_N}&=\\frac{1}{\\sqrt{Bt}} \\\\\n",
    "\\frac{1}{\\sigma_N}&=\\frac{1}{P_N}\\sqrt{Bt},\n",
    "\\tag{7.5}\n",
    "\\end{align*}$$\n",
    "\n",
    "where on the last line I have rearranged the terms in a manner that will prove convenient in the ensuing discussion. The important application of this result to our work is in the use of power spectra to express the output of detectors in a series of frequency bands, each of bandwidth $B$, where the power spectrum is fashioned out of data taken over a time interval $t$. Each of these frequency bands, or bins, has an average power $P_N$. They are all the same because Johnson noise is approximately independent of frequency in the low frequency limit. However, what you see in a power spectrum is a jagged line about an average value, because of the fluctuations in the measured power about the average power. The root mean square of these fluctuations is $\\sigma_N$. It gets smaller if you either increase the amount of time over which the power was estimated, or you increase the bandwidth of each of the bins.\n",
    "\n",
    "Now, suppose one of the bins contains a small signal $P_S$ in addition to the noise. This signal is always present, and it is only present, for simplicity, in one of the bands. As you acquire power for longer and longer, the root mean square fluctuation between bins drops as the square root of the integration time. Put simply, the power spectrum gets smoother, and if you integrate for long enough, the signal becomes visible above the fluctuations in the noise. \n",
    "\n",
    "We define the signal to noise ratio, or $\\rm SNR$, as the ratio of the signal power $P_S$ to the root mean square noise fluctuation, $\\sigma_N$. Inserting $P_S$ into Equation 7.5, we obtain the form in which the radiometer equation is usually written for its applications to radio astronomy and axion searches.\n",
    "\n",
    "$$\\begin{align*}\n",
    "{\\rm SNR}=\\frac{P_S}{\\sigma_N}=\\frac{P_S}{P_N}\\sqrt{Bt}. \n",
    "\\tag{7.6}\n",
    "\\end{align*}$$\n",
    "\n",
    "### Application to axion detection\n",
    "\n",
    "Let us see why this is so useful for axion searches. Suppose your signal power over the bandwidth of the axion signal is a tenth that of the raw noise power. This means that $P_S/P_N=0.1$. Suppose the axion signal covers a bandwidth of $\\rm 1\\,kHz$. Let us say that you can make out the axion signal when it is four times the height of the root mean square noise fluctuations, so that the target $\\rm SNR$ is $4$. How long do you have to integrate to achieve this signal to noise ratio? Equation 7.6 tells us the answer. It becomes $4=0.1\\sqrt{1000t}$, so $1000t=40^2=1600$, therefore $t=1.6\\,{\\rm s}$. So in 1.6 seconds, even with a raw signal power that is only a tenth that of the raw noise power, you'll still be able to see the axion signal as a small power excess on top of the fluctuations in the surrounding noise floor. \n",
    "\n",
    "However, the win by averaging over long times for weak signals is a slow one because of the square root. Suppose instead $P_S/P_N$ were $0.01$. In this case you have $4=0.01\\sqrt{1000t}$, so that $1000t=1.6\\times10^5$, You need to integrate for $\\rm 160\\,s$ to achieve an $\\rm SNR$ of 4. If the integration times get too long, then aspects of your detector may start to drift, and this drift will spoil the effect of the averaging on the noise fluctuations by causing the baseline, or noise floor, to drift around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1629876",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf9790d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}